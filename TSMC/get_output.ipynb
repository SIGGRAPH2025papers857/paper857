{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:18.502498Z",
     "start_time": "2025-01-13T22:58:17.741034Z"
    }
   },
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import trimesh\n",
    "import subprocess\n",
    "import os\n",
    "import time"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:20.630800Z",
     "start_time": "2025-01-13T22:58:20.426205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "static_parts = o3d.io.read_triangle_mesh(fr\"G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0001.obj\")\n",
    "static_parts.compute_vertex_normals()"
   ],
   "id": "bd58c366a8d86379",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 71221 points and 139834 triangles."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:21.739882Z",
     "start_time": "2025-01-13T22:58:21.715435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dynamic_deformed = o3d.io.read_triangle_mesh(r\"G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\drinking\\reference/deformed_reference_mesh_007.obj\")\n",
    "dynamic_deformed.compute_vertex_normals()\n",
    "dynamic_deformed.paint_uniform_color([1, 0, 0])"
   ],
   "id": "10c80814d64277a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 6555 points and 9000 triangles."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:23.012059Z",
     "start_time": "2025-01-13T22:58:22.868462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dynamic_deformed_meshes = []\n",
    "for i in range(1, 8):\n",
    "    dynamic_deformed = o3d.io.read_triangle_mesh(fr\"G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\drinking\\reference/deformed_reference_mesh_{i:03}.obj\")\n",
    "    dynamic_deformed.compute_vertex_normals()\n",
    "    dynamic_deformed.paint_uniform_color([1, 0, 0])\n",
    "    dynamic_deformed_meshes.append(dynamic_deformed)"
   ],
   "id": "cae09aa79f376981",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:24.517887Z",
     "start_time": "2025-01-13T22:58:24.219088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dynamic_meshes = []\n",
    "for i in range(1, 8):\n",
    "    dynamic = o3d.io.read_triangle_mesh(fr\"G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Dynamic/dynamic_mesh_0{i:03}.obj\")\n",
    "    dynamic.compute_vertex_normals()\n",
    "    dynamic.paint_uniform_color([0.4, 0.4, 0.4])\n",
    "    dynamic_meshes.append(dynamic)"
   ],
   "id": "a181c370de8c165",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T20:12:15.422493Z",
     "start_time": "2024-12-09T20:11:58.394035Z"
    }
   },
   "cell_type": "code",
   "source": "o3d.visualization.draw_geometries([dynamic_deformed_meshes[6], dynamic_meshes[6]])",
   "id": "bac99de0fcc7cb11",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:27.057207Z",
     "start_time": "2025-01-13T22:58:27.043085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def subdivide_surface_fitting(decimated_mesh, target_mesh, iterations=1):\n",
    "    subdivided_mesh = o3d.geometry.TriangleMesh.subdivide_midpoint(decimated_mesh, number_of_iterations=iterations)\n",
    "    print(subdivided_mesh)\n",
    "    subdivided_mesh.compute_vertex_normals()\n",
    "    \n",
    "    pcd_target = o3d.geometry.PointCloud()\n",
    "    pcd_target.points = o3d.utility.Vector3dVector(target_mesh.vertices)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_target)\n",
    "    subdivided_vertices = np.array(subdivided_mesh.vertices)\n",
    "    target_vertices = np.array(target_mesh.vertices)\n",
    "    fitting_vertices = deepcopy(subdivided_vertices)\n",
    "    \n",
    "    for i in range(0, len(subdivided_vertices)):\n",
    "        [k, index, _] = pcd_tree.search_knn_vector_3d(subdivided_vertices[i], 1)\n",
    "        fitting_vertices[i] = target_vertices[np.asarray(index)]\n",
    "        \n",
    "    subdivided_mesh.vertices = o3d.utility.Vector3dVector(fitting_vertices)\n",
    "    return subdivided_mesh"
   ],
   "id": "add3fc9cbd1c9c64",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:28.634609Z",
     "start_time": "2025-01-13T22:58:28.614352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_triangle_mesh_with_trimesh(avatar_name,enable_post_processing=False):\n",
    "    # EDIT: next 4 lines replace to maintain order even in case of degenerate and non referenced\n",
    "    # scene_patch = trimesh.load(avatar_name,process=enable_post_processing)\n",
    "    if enable_post_processing:\n",
    "        scene_patch = trimesh.load(avatar_name,process=True)\n",
    "    else:\n",
    "        scene_patch = trimesh.load(avatar_name,process=False,maintain_order=True) \n",
    "    mesh = o3d.geometry.TriangleMesh(\n",
    "        o3d.utility.Vector3dVector(scene_patch.vertices),\n",
    "        o3d.utility.Vector3iVector(scene_patch.faces)\n",
    "    ) \n",
    "    if scene_patch.vertex_normals.size:\n",
    "        mesh.vertex_normals = o3d.utility.Vector3dVector(scene_patch.vertex_normals.copy())\n",
    "    if scene_patch.visual.defined:\n",
    "        # either texture or vertex colors if no uvs present.\n",
    "        if scene_patch.visual.kind == 'vertex':\n",
    "            mesh.vertex_colors = o3d.utility.Vector3dVector(scene_patch.visual.vertex_colors[:,:3]/255) # no alpha channel support\n",
    "        elif scene_patch.visual.kind == 'texture':\n",
    "            uv = scene_patch.visual.uv\n",
    "            if uv.shape[0] == scene_patch.vertices.shape[0]:\n",
    "                mesh.triangle_uvs = o3d.utility.Vector2dVector(uv[scene_patch.faces.flatten()])\n",
    "            elif uv.shape[0] != scene_patch.faces.shape[0] * 3:\n",
    "                assert False\n",
    "            else:\n",
    "                mesh.triangle_uvs = o3d.utility.Vector2dVector(uv)\n",
    "                if scene_patch.visual.material is not None and scene_patch.visual.material.image is not None:\n",
    "                    if scene_patch.visual.material.image.mode == 'RGB':\n",
    "                        mesh.textures = [o3d.geometry.Image(np.asarray(scene_patch.visual.material.image))]\n",
    "                    else:\n",
    "                        assert False\n",
    "        else:\n",
    "            assert False\n",
    "    return mesh"
   ],
   "id": "c4f1b25b589f3214",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:30.412844Z",
     "start_time": "2025-01-13T22:58:30.392619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_D1_psnr(original_mesh, decoded_mesh):\n",
    "    \n",
    "    original_vertices = np.array(original_mesh.vertices)\n",
    "    #original_vertices = normalize_vertices(original_vertices)\n",
    "    decoded_vertices = np.array(decoded_mesh.vertices)\n",
    "    #decoded_vertices = normalize_vertices(decoded_vertices)\n",
    "    \n",
    "    pcd_original = o3d.geometry.PointCloud()\n",
    "    pcd_original.points = o3d.utility.Vector3dVector(original_vertices)\n",
    "    \n",
    "    pcd_decoded = o3d.geometry.PointCloud()\n",
    "    pcd_decoded.points = o3d.utility.Vector3dVector(decoded_vertices)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_decoded)\n",
    "    \n",
    "    MSE = 0\n",
    "    for i in range(0, len(original_vertices)):\n",
    "        [k, index, _] = pcd_tree.search_knn_vector_3d(original_vertices[i], 1)\n",
    "        MSE += np.square(np.linalg.norm(original_vertices[i] - decoded_vertices[index]))\n",
    "    MSE = MSE / len(original_vertices)\n",
    "    #print(\"D1 mse:\",MSE)\n",
    "    aabb = pcd_original.get_axis_aligned_bounding_box()\n",
    "    min_bound = aabb.get_min_bound()\n",
    "\n",
    "    max_bound = aabb.get_max_bound()\n",
    "\n",
    "    signal_peak = np.linalg.norm(max_bound - min_bound)\n",
    "    #print(signal_peak)\n",
    "    psnr = 20 * np.log10(signal_peak) - 10 * np.log10(MSE)\n",
    "    #print(psnr)\n",
    "    return psnr\n",
    "\n",
    "def compute_D2_psnr(original_mesh, decoded_mesh):\n",
    "    \n",
    "    decoded_mesh.compute_vertex_normals()\n",
    "    original_vertices = np.array(original_mesh.vertices)\n",
    "    decoded_vertices = np.array(decoded_mesh.vertices)\n",
    "    \n",
    "    pcd_original = o3d.geometry.PointCloud()\n",
    "    pcd_original.points = o3d.utility.Vector3dVector(original_vertices)\n",
    "    \n",
    "    \n",
    "    pcd_decoded = o3d.geometry.PointCloud()\n",
    "    pcd_decoded.points = o3d.utility.Vector3dVector(decoded_vertices)\n",
    "    pcd_decoded.normals = o3d.utility.Vector3dVector(decoded_mesh.vertex_normals)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_decoded)\n",
    "    \n",
    "    MSE = 0\n",
    "    for i in range(0, len(original_vertices)):\n",
    "        [k, index, _] = pcd_tree.search_knn_vector_3d(original_vertices[i], 1)\n",
    "        MSE += np.square(np.dot((original_vertices[i] - decoded_vertices[index])[0], np.array(pcd_decoded.normals)[index][0]))\n",
    "    MSE = MSE / len(original_vertices)\n",
    "\n",
    "    aabb = pcd_original.get_axis_aligned_bounding_box()\n",
    "    min_bound = aabb.get_min_bound()\n",
    "\n",
    "    max_bound = aabb.get_max_bound()\n",
    "\n",
    "    signal_peak = np.linalg.norm(max_bound - min_bound)\n",
    "    psnr = 20 * np.log10(signal_peak) - 10 * np.log10(MSE)\n",
    "    \n",
    "    return psnr\n",
    "\n",
    "def compute_MSE_RMSE(original_mesh, decoded_mesh):\n",
    "    \n",
    "    original_vertices = np.array(original_mesh.vertices)\n",
    "    #original_vertices = normalize_vertices(original_vertices)\n",
    "    decoded_vertices = np.array(decoded_mesh.vertices)\n",
    "    #decoded_vertices = normalize_vertices(decoded_vertices)\n",
    "    \n",
    "    pcd_original = o3d.geometry.PointCloud()\n",
    "    pcd_original.points = o3d.utility.Vector3dVector(original_vertices)\n",
    "    \n",
    "    pcd_decoded = o3d.geometry.PointCloud()\n",
    "    pcd_decoded.points = o3d.utility.Vector3dVector(decoded_vertices)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_decoded)\n",
    "    \n",
    "    MSE = 0\n",
    "    for i in range(0, len(original_vertices)):\n",
    "        [k, index, _] = pcd_tree.search_knn_vector_3d(original_vertices[i], 1)\n",
    "        MSE += np.square(np.linalg.norm(original_vertices[i] - decoded_vertices[index]))\n",
    "    MSE = MSE / len(original_vertices)\n",
    "    #print(\"MSE:\", MSE)\n",
    "    RMSE =np.sqrt(MSE)\n",
    "    \n",
    "    return np.log10(MSE), np.log10(RMSE)\n",
    "\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "def compute_Hausdorff(original_mesh, decoded_mesh):\n",
    "    original_vertices = np.array(original_mesh.vertices)\n",
    "    decoded_vertices = np.array(decoded_mesh.vertices)\n",
    "    hausdorff = directed_hausdorff(original_vertices, decoded_vertices)\n",
    "    return hausdorff[0] * 1e4\n"
   ],
   "id": "d10ca13c9b0a0975",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:48.571274Z",
     "start_time": "2025-01-13T22:58:44.990601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, 8):\n",
    "    dynamic_deformed = o3d.io.read_triangle_mesh(fr\"G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\drinking\\reference/deformed_reference_mesh_{i:03}.obj\")\n",
    "    original_i = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene/mesh_000{i:1}.obj')\n",
    "\n",
    "    print(dynamic_deformed)\n",
    "    print(original_i)\n",
    "    dynamic_deformed.compute_vertex_normals()\n",
    "    original_i.compute_vertex_normals()\n",
    "    #o3d.visualization.draw_geometries([reconstruct_dancer_i])\n",
    "    fitting_mesh_dancer_i = subdivide_surface_fitting(dynamic_deformed, original_i, 1)\n",
    "    #print(np.array(fitting_mesh_dancer_i.triangles))\n",
    "    o3d.io.write_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\drinking\\reference/fitting_mesh_{i:03}.obj', fitting_mesh_dancer_i, write_vertex_normals=False, write_vertex_colors=False, write_triangle_uvs=False)\n",
    "    #o3d.visualization.draw_geometries([fitting_mesh_dancer_i])"
   ],
   "id": "f395b15f16928a3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 84034 points and 168589 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 83905 points and 168328 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 83881 points and 168301 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 82407 points and 165406 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 81981 points and 164452 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 83469 points and 167506 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n",
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "TriangleMesh with 82963 points and 166481 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles.\n",
      "[Open3D WARNING] Write OBJ can not include triangle normals.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:50.346769Z",
     "start_time": "2025-01-13T22:58:50.316347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_decimated_reference_mesh = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decimated_reference_mesh.obj', enable_post_processing=False)\n",
    "print(loaded_decimated_reference_mesh)\n",
    "loaded_decimated_reference_mesh_vertices = np.array(loaded_decimated_reference_mesh.vertices)\n",
    "print(np.array(loaded_decimated_reference_mesh.triangles))\n",
    "loaded_decimated_reference_mesh_vertices"
   ],
   "id": "244953bb11dae84f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 6555 points and 9000 triangles.\n",
      "[[   0    1    2]\n",
      " [   3    4    5]\n",
      " [   0    2    6]\n",
      " ...\n",
      " [3680 3583 3661]\n",
      " [3654 3644 3661]\n",
      " [3684 3654 3661]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.684466  ,  1.83513999, -0.88690299],\n",
       "       [-0.67031801,  1.80734003, -0.89626801],\n",
       "       [-0.65697098,  1.82257009, -0.89857602],\n",
       "       ...,\n",
       "       [-0.69024301,  1.86600995,  2.08393002],\n",
       "       [-0.25770801,  2.20842004, -0.684578  ],\n",
       "       [-0.16192999,  0.86249697,  0.26020899]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:53.200684Z",
     "start_time": "2025-01-13T22:58:53.189042Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = \"drinking\"",
   "id": "556871a46db377ac",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:58:55.348213Z",
     "start_time": "2025-01-13T22:58:54.424313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subdivided_decimated_reference_mesh = o3d.geometry.TriangleMesh.subdivide_midpoint(loaded_decimated_reference_mesh, number_of_iterations=1)\n",
    "#print(subdivided_decimated_reference_mesh)\n",
    "subdivided_decimated_reference_mesh_vertices = np.array(subdivided_decimated_reference_mesh.vertices)\n",
    "#o3d.visualization.draw_geometries([subdivided_decimated_reference_mesh])\n",
    "displacements = []\n",
    "for i in range(1, 8):\n",
    "    offset = 0\n",
    "    fitting_mesh_dancer_i = read_triangle_mesh_with_trimesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\{dataset}\\reference/fitting_mesh_{i+offset:03}.obj', enable_post_processing=False)\n",
    "    #fitting_mesh_dancer_i = fitting_mesh_dancer[i]\n",
    "    print(fitting_mesh_dancer_i, subdivided_decimated_reference_mesh)\n",
    "    fitting_mesh_vertices = np.array(fitting_mesh_dancer_i.vertices)\n",
    "    #print(np.array(fitting_mesh_dancer_i.triangles))\n",
    "    displacement_i = fitting_mesh_vertices - subdivided_decimated_reference_mesh_vertices\n",
    "    np.savetxt(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\{dataset}\\reference/displacements_{dataset}_{i+offset:03}.txt', displacement_i, fmt='%8f')\n",
    "    displacements.append(displacement_i)\n",
    "\n"
   ],
   "id": "4aa62a332854fece",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n",
      "TriangleMesh with 22141 points and 36000 triangles. TriangleMesh with 22141 points and 36000 triangles.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:59:29.444703Z",
     "start_time": "2025-01-13T22:59:29.410604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_reference_mesh_path = fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decimated_reference_mesh.obj'\n",
    "input_decimated_reference_mesh = read_triangle_mesh_with_trimesh(input_reference_mesh_path, enable_post_processing=False)\n",
    "print(input_decimated_reference_mesh)\n",
    "np.array(input_decimated_reference_mesh.vertices)"
   ],
   "id": "939c5fd1e37979d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 6555 points and 9000 triangles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.655131,  1.77801 , -0.898511],\n",
       "       [-0.670318,  1.80734 , -0.896268],\n",
       "       [-0.684466,  1.83514 , -0.886903],\n",
       "       ...,\n",
       "       [-0.694706,  1.69875 ,  2.09997 ],\n",
       "       [-0.690243,  1.77677 ,  2.09997 ],\n",
       "       [-0.690243,  1.86601 ,  2.08393 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:59:32.639558Z",
     "start_time": "2025-01-13T22:59:32.517527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/encoded_decimated_reference_mesh.drc'\n",
    "result = subprocess.run([\n",
    "                            r'G:\\Github\\draco\\build\\Debug\\draco_encoder',\n",
    "                            '-i', input_reference_mesh_path,\n",
    "                            '-o', output_path,\n",
    "                            '-qp', str('20'),\n",
    "                            '-cl', '7'\n",
    "                            ], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)"
   ],
   "id": "c4462d6c2ae1da1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder options:\n",
      "  Compression level = 7\n",
      "  Positions: Quantization = 20 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/encoded_decimated_reference_mesh.drc (76 ms to encode).\n",
      "\n",
      "Encoded size = 39435 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:59:37.836183Z",
     "start_time": "2025-01-13T22:59:37.755441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = subprocess.run([\n",
    "                            r'G:\\Github\\draco\\build\\Debug\\draco_decoder',\n",
    "                            '-i', output_path,\n",
    "                            '-o', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decode_decimated_reference_mesh.obj'\n",
    "                            ], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)"
   ],
   "id": "e27395c12b559481",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decode_decimated_reference_mesh.obj (13 ms to decode)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T22:59:58.881643Z",
     "start_time": "2025-01-13T22:59:40.385799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, 8):\n",
    "    input_static_mesh_path = fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0{i:03}.obj'\n",
    "    output_static_mesh_path = fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0{i:03}.drc'\n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_encoder',\n",
    "                                '-i', input_static_mesh_path,\n",
    "                                '-o', output_static_mesh_path,\n",
    "                                '-qp', str('14'),\n",
    "                                '-cl', '10'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "    \n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_decoder',\n",
    "                                '-i', output_static_mesh_path,\n",
    "                                '-o', fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0{i:03}_decoded.obj'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)"
   ],
   "id": "5f85e0ad5fda6176",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0001.drc (1406 ms to encode).\n",
      "\n",
      "Encoded size = 198930 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0001_decoded.obj (350 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0002.drc (1352 ms to encode).\n",
      "\n",
      "Encoded size = 198534 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0002_decoded.obj (343 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0003.drc (1329 ms to encode).\n",
      "\n",
      "Encoded size = 198510 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0003_decoded.obj (340 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0004.drc (1310 ms to encode).\n",
      "\n",
      "Encoded size = 196081 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0004_decoded.obj (336 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0005.drc (1284 ms to encode).\n",
      "\n",
      "Encoded size = 194010 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0005_decoded.obj (332 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0006.drc (1317 ms to encode).\n",
      "\n",
      "Encoded size = 197254 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0006_decoded.obj (342 ms to decode)\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 14 bits\n",
      "\n",
      "Encoded mesh saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0007.drc (1305 ms to encode).\n",
      "\n",
      "Encoded size = 196818 bytes\n",
      "\n",
      "\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0007_decoded.obj (337 ms to decode)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:02.602050Z",
     "start_time": "2025-01-13T23:00:02.377373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, 8):\n",
    "    offset = 0\n",
    "    displacement = np.loadtxt(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\{dataset}\\reference/displacements_{dataset}_{i+offset:03}.txt')\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points = displacement\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    print(pcd)\n",
    "    #o3d.io.write_point_cloud(r'G:\\VS2022Projects\\tvm-editing-master\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Dancer\\reference_mesh/dis.ply', pcd)\n",
    "    points=np.asarray(pcd.points)\n",
    "    dtype = o3d.core.float32\n",
    "    p_tensor = o3d.core.Tensor(points, dtype=dtype)\n",
    "    pc = o3d.t.geometry.PointCloud(p_tensor)\n",
    "    o3d.t.io.write_point_cloud(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/dis_{dataset}_{i+offset:03}.ply', pc, write_ascii=True)"
   ],
   "id": "c63938525fe5a15b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n",
      "PointCloud with 22141 points.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:07.718213Z",
     "start_time": "2025-01-13T23:00:06.683147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "qp = 12\n",
    "times = []\n",
    "for i in range(1, 8):\n",
    "    offset = 0\n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_encoder',\n",
    "                                #r'G:\\Github\\draco\\buildforSequenceEncoding\\Debug\\draco_encoder',\n",
    "                                '-point_cloud',\n",
    "                                '-i', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/dis_{dataset}_{i+offset:03}.ply',\n",
    "                                '-o', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/dis_{dataset}_{i+offset:03}.drc',\n",
    "                                '-qp', str(qp),\n",
    "                                '-cl', '10'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    time_pattern = re.compile(r\"\\((\\d+) ms to encode\\)\")\n",
    "    match = time_pattern.search(result.stdout)\n",
    "    if match:\n",
    "        times.append(int(match.group(1)))\n",
    "    \n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_encoder',\n",
    "                                #r'G:\\Github\\draco\\buildforSequenceEncoding\\Debug\\draco_encoder',\n",
    "                                '-point_cloud',\n",
    "                                '-i', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/dis_{dataset}_{i+offset:03}.ply',\n",
    "                                '-o', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/dis_{dataset}_{i+offset:03}_0.drc',\n",
    "                                '-qp', str(qp),\n",
    "                                '-cl', '0'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "\n",
    "        \n",
    "if times:\n",
    "    mean_time = sum(times) / len(times)\n",
    "    print(f\"Mean encoding time: {mean_time:.2f} ms\")\n",
    "print(f\"Average encoding time for qp {qp}: {mean_time:.2f} seconds\\n\\n\")"
   ],
   "id": "362b65562e4ad7fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_001.drc (32 ms to encode).\n",
      "\n",
      "Encoded size = 33070 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_001_0.drc (6 ms to encode).\n",
      "\n",
      "Encoded size = 72122 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_002.drc (29 ms to encode).\n",
      "\n",
      "Encoded size = 46185 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_002_0.drc (8 ms to encode).\n",
      "\n",
      "Encoded size = 86213 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_003.drc (28 ms to encode).\n",
      "\n",
      "Encoded size = 42585 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_003_0.drc (9 ms to encode).\n",
      "\n",
      "Encoded size = 84125 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_004.drc (32 ms to encode).\n",
      "\n",
      "Encoded size = 32818 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_004_0.drc (8 ms to encode).\n",
      "\n",
      "Encoded size = 72765 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_005.drc (35 ms to encode).\n",
      "\n",
      "Encoded size = 27330 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_005_0.drc (7 ms to encode).\n",
      "\n",
      "Encoded size = 67484 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_006.drc (35 ms to encode).\n",
      "\n",
      "Encoded size = 26533 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_006_0.drc (8 ms to encode).\n",
      "\n",
      "Encoded size = 66110 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 10\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_007.drc (35 ms to encode).\n",
      "\n",
      "Encoded size = 27221 bytes\n",
      "\n",
      "\n",
      "Encoder options:\n",
      "  Compression level = 0\n",
      "  Positions: Quantization = 12 bits\n",
      "\n",
      "Encoded point cloud saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/dis_drinking_007_0.drc (8 ms to encode).\n",
      "\n",
      "Encoded size = 66599 bytes\n",
      "\n",
      "For better compression, increase the compression level up to '-cl 10' .\n",
      "\n",
      "\n",
      "Mean encoding time: 32.29 ms\n",
      "Average encoding time for qp 12: 32.29 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:11.187531Z",
     "start_time": "2025-01-13T23:00:10.748179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "times= []\n",
    "for i in range(1, 8):\n",
    "    offset = 0\n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_decoder',\n",
    "                                '-i', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/dis_{dataset}_{i+offset:03}_0.drc',\n",
    "                                '-o', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/decoded_{dataset}_{i+offset:03}_displacements.ply'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    result = subprocess.run([\n",
    "                                r'G:\\Github\\draco\\build\\Debug\\draco_decoder',\n",
    "                                '-i', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/dis_{dataset}_{i+offset:03}.drc',\n",
    "                                '-o', fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/decoded_{dataset}_{i+offset:03}_displacements_10.ply'\n",
    "                                ], capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    time_pattern = re.compile(r\"\\((\\d+) ms to decode\\)\")\n",
    "    match = time_pattern.search(result.stdout)\n",
    "    if match:\n",
    "        times.append(int(match.group(1)))\n",
    "        \n",
    "if times:\n",
    "    mean_time = sum(times) / len(times)\n",
    "    print(f\"Mean encoding time: {mean_time:.2f} ms\")\n",
    "print(f\"Average encoding time for qp {qp}: {mean_time:.2f} seconds\\n\\n\")"
   ],
   "id": "5fe2137dc31a913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_001_displacements.ply (3 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_001_displacements_10.ply (13 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_002_displacements.ply (4 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_002_displacements_10.ply (14 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_003_displacements.ply (4 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_003_displacements_10.ply (12 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_004_displacements.ply (4 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_004_displacements_10.ply (14 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_005_displacements.ply (3 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_005_displacements_10.ply (13 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_006_displacements.ply (4 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_006_displacements_10.ply (14 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_007_displacements.ply (4 ms to decode)\n",
      "\n",
      "Decoded geometry saved to G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\drinking\\reference_mesh/GoF5/decoded_drinking_007_displacements_10.ply (13 ms to decode)\n",
      "\n",
      "Mean encoding time: 13.29 ms\n",
      "Average encoding time for qp 12: 13.29 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:13.230922Z",
     "start_time": "2025-01-13T23:00:13.227910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_bitrate(file_size, duration):\n",
    "    return file_size * 8 / duration"
   ],
   "id": "645ed894e7d4dc9e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:14.703915Z",
     "start_time": "2025-01-13T23:00:14.690354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_frames = 7\n",
    "frame_rate = 30"
   ],
   "id": "13859e5ad10bb81c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:16.001503Z",
     "start_time": "2025-01-13T23:00:15.996491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_size = 0\n",
    "offset = 1\n",
    "for i in range(0, 7):\n",
    "    displacement_file_path = fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/dis_{dataset}_{i+offset:03}_0.drc'\n",
    "    displacement_file_size = os.path.getsize(displacement_file_path)\n",
    "    total_size += displacement_file_size\n",
    "reference_mesh_file_path = fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/encoded_decimated_reference_mesh.drc'\n",
    "reference_mesh_file_size = os.path.getsize(reference_mesh_file_path)\n",
    "total_size += reference_mesh_file_size\n",
    "total_duration = number_frames / frame_rate\n",
    "total_size += os.path.getsize(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0003.drc')\n",
    "overall_bitrate = calculate_bitrate(total_size, total_duration)\n",
    "\n",
    "print(f\"Total Size of {number_frames} DRC Files: {total_size} bytes\")\n",
    "print(f\"Overall Bitrate: {overall_bitrate} bits per second\")\n",
    "\n",
    "bitrate_kbps = overall_bitrate / 1000\n",
    "bitrate_mbps = overall_bitrate / 1000000\n",
    "\n",
    "\n",
    "print(f\"Overall Bitrate: {bitrate_kbps:.2f} Kbps\")\n",
    "print(f\"Overall Bitrate: {bitrate_mbps:.2f} Mbps\")"
   ],
   "id": "b4a8e8ffc49d58a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size of 7 DRC Files: 753363 bytes\n",
      "Overall Bitrate: 25829588.57142857 bits per second\n",
      "Overall Bitrate: 25829.59 Kbps\n",
      "Overall Bitrate: 25.83 Mbps\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:17.647771Z",
     "start_time": "2025-01-13T23:00:17.593291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_displacements = []\n",
    "decoded_displacements = []\n",
    "dis_plys= []\n",
    "for i in range(0, 7):\n",
    "    offset = 1\n",
    "    original_displacement = np.loadtxt(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\output\\{dataset}\\reference/displacements_{dataset}_{i+offset:03}.txt')\n",
    "    decoded_displacement = o3d.io.read_point_cloud(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/decoded_{dataset}_{i+offset:03}_displacements.ply')\n",
    "    dis_ply = o3d.io.read_point_cloud(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\reference_mesh/GoF{5}/decoded_{dataset}_{i+offset:03}_displacements.ply')\n",
    "    original_displacements.append(original_displacement)\n",
    "    decoded_displacements.append(decoded_displacement)\n",
    "    dis_plys.append(dis_ply)\n",
    "print(decoded_displacements.__len__())"
   ],
   "id": "bb2b8335965d9fd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:00:29.289308600Z",
     "start_time": "2025-01-13T23:00:24.389629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d1s = []\n",
    "d2s = []\n",
    "mses = []\n",
    "rmses = []\n",
    "hausdorffs = []\n",
    "original_static = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0003_decoded.obj', enable_post_processing=False)\n",
    "for m in range(0, 7):\n",
    "    decode_decimated_reference_mesh = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decode_decimated_reference_mesh.obj', enable_post_processing=False)\n",
    "    #print(decode_decimated_reference_mesh)\n",
    "    np.array(decode_decimated_reference_mesh.vertices)\n",
    "    start = time.time()\n",
    "    subdivided_decoded_mesh = o3d.geometry.TriangleMesh.subdivide_midpoint(decode_decimated_reference_mesh, number_of_iterations=1)\n",
    "    mesh = deepcopy(subdivided_decoded_mesh)\n",
    "    triangles = deepcopy(mesh.triangles)\n",
    "    end = time.time()\n",
    "    print(\"subdivision time:\", end - start)\n",
    "    #print(subdivided_decoded_mesh)\n",
    "    input_decimated_reference_mesh = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\reference_mesh/decimated_reference_mesh.obj', enable_post_processing=False)\n",
    "    subdivided_mesh = o3d.geometry.TriangleMesh.subdivide_midpoint(input_decimated_reference_mesh, number_of_iterations=1)\n",
    "    #print(subdivided_mesh)\n",
    "    #original_static = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\{dataset}\\meshes/mitch_fr0{m+offset:03}.obj')\n",
    "    #original_dancer = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\tvm-editing\\TVMEditor.Test\\bin\\Release\\net5.0\\Data\\Drinking\\meshes/dynamic_mesh_0{m+offset:03}.obj')\n",
    "    original_dancer = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\meshes\\good/mesh_0{m+offset:03}.obj')\n",
    "    original_static = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0{m+offset:03}_decoded.obj', enable_post_processing=False)\n",
    "    #print(original_dancer)\n",
    "    decoded_mesh_vertices = np.array(decode_decimated_reference_mesh.vertices)\n",
    "    subdivided_decoded_mesh_vertices = np.array(subdivided_decoded_mesh.vertices)\n",
    "    \n",
    "    \n",
    "    displacement = np.array(decoded_displacements[m].points)\n",
    "    \n",
    "    dis_indexer = o3d.geometry.PointCloud()\n",
    "    dis_indexer.points = o3d.utility.Vector3dVector(original_displacements[m])\n",
    "    dis_tree = o3d.geometry.KDTreeFlann(dis_indexer)\n",
    "    \n",
    "    pcd_indexer = o3d.geometry.PointCloud()\n",
    "    pcd_indexer.points = o3d.utility.Vector3dVector(subdivided_mesh.vertices)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd_indexer)\n",
    "    \n",
    "    reordered_vertices = deepcopy(subdivided_decoded_mesh_vertices)\n",
    "    start = time.time()\n",
    "    for i in range(0, len(subdivided_decoded_mesh_vertices)):\n",
    "        [k, index, _] = pcd_tree.search_knn_vector_3d(subdivided_decoded_mesh_vertices[i], 1)\n",
    "        [j, dis_index, _] = dis_tree.search_knn_vector_3d(original_displacements[m][index[0]], 1)\n",
    "        #print(displacement[dis_index], original_displacements[index[0]])\n",
    "        reordered_vertices[i] += displacement[dis_index[0]]\n",
    "    end = time.time()\n",
    "    print(\"rematching time:\", end - start)\n",
    "    reconstruct_mesh = o3d.geometry.TriangleMesh()\n",
    "    reconstruct_mesh.triangles = subdivided_decoded_mesh.triangles\n",
    "    reconstruct_mesh.vertices = o3d.utility.Vector3dVector(reordered_vertices)\n",
    "    reconstruct_mesh += original_static\n",
    "    reconstruct_mesh.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([reconstruct_mesh])\n",
    "    o3d.io.write_triangle_mesh(fr'G:\\PycharmProjects\\Mesh_Editing\\Results\\decode_Ours\\{dataset}/GoF{5}/decoded_{dataset}_fr0{m+offset:03}.obj', reconstruct_mesh, write_vertex_normals=False, write_vertex_colors=False, write_triangle_uvs=False)\n",
    "    \n",
    "    d1 = max(compute_D1_psnr(original_dancer, reconstruct_mesh), compute_D1_psnr(reconstruct_mesh, original_dancer))\n",
    "    print(\"D1:\", d1)\n",
    "    d1s.append(d1)\n",
    "    \n",
    "    #d2 = max(compute_D2_psnr(original_dancer, reconstruct_mesh), compute_D2_psnr(reconstruct_mesh, original_dancer))\n",
    "    #print(\"D2:\", d2)\n",
    "    #d2s.append(d2)\n",
    "\n",
    "    #logmse1, logrmse1 = compute_MSE_RMSE(original_dancer, reconstruct_mesh)\n",
    "    #logmse2, logrmse2 = compute_MSE_RMSE(reconstruct_mesh, original_dancer)\n",
    "    #logmse = min(logmse1, logmse2)\n",
    "    #logrmse = min(logrmse1, logrmse2)\n",
    "    #print(\"log10 of mse:\", logmse, \", log10 of rmse:\", logrmse)\n",
    "    #mses.append(logmse)\n",
    "    #rmses.append(logrmse)\n",
    "    \n",
    "    #hausdorff = compute_Hausdorff(original_dancer, reconstruct_mesh)\n",
    "    #print(\"Hausdorff distance:\", hausdorff)\n",
    "    #hausdorffs.append(hausdorff)\n",
    "o3d.visualization.draw_geometries([reconstruct_mesh])\n",
    "print(\"average D1:\", np.mean(d1s))\n",
    "#print(\"average D2:\", np.mean(d2s))\n",
    "print(\"average log10 of mse:\", np.mean(mses))\n",
    "print(\"average log10 of rmse:\", np.mean(rmses))\n",
    "print(\"average Hausdorff:\", np.mean(hausdorffs))"
   ],
   "id": "2e052eb6f682d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdivision time: 0.002004861831665039\n",
      "rematching time: 0.15549159049987793\n",
      "[Open3D WARNING] Write OBJ failed: unable to open file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T21:14:57.648473Z",
     "start_time": "2024-12-09T21:14:20.483277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_static = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0001.obj', enable_post_processing=False)\n",
    "original_static2 = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0002.obj', enable_post_processing=False)\n",
    "original_static3 = o3d.io.read_triangle_mesh(fr'G:\\VS2022Projects\\arap-volume-tracking-main\\data\\scene\\Static/static_mesh_0003.obj', enable_post_processing=False)\n",
    "\n",
    "d1 = max(compute_D1_psnr(original_static, original_static3), compute_D1_psnr(original_static3, original_static))\n",
    "print(\"D1:\", d1)\n",
    "d1s.append(d1)\n",
    "\n",
    "d2 = max(compute_D2_psnr(original_static, original_static3), compute_D2_psnr(original_static3, original_static))\n",
    "print(\"D2:\", d2)\n",
    "d2s.append(d2)\n"
   ],
   "id": "4816ba98c2cb79b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1: 56.351319582457926\n",
      "D2: 66.356072542004\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
